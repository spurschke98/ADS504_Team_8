Abstract: Predictive modeling provides exciting solutions and applications in many fields ranging from targeted ads in marketing to fraud detection in credit card usage. While these applications may attract the most attention, much work in failure analysis is also the more humble and tedious work of analyzing large and publicly available data sources for macro level data relationships that can guide other aspects of policy that can saves lives, such as Disaster Management and Recovery Sources. Here we have investigated the application of machine learning tools to a unique source of public data from the 2015 Nepal Earthquake to demonstrate the utility of these approaches beyond what has already been shown in the literature. Using various linear, nonlinear, parametric, and non-parametric machine learning algorithms we showed that there is no significant difference in performance among models using five target classes. Binary classification models, generated and learned by aggregating classes to make a binary target, were learned and compared to multinomial classification models for sake of completeness and research. The strengths and weakness of the project were discussed, and future research recommendations with regard to this dataset were addressed. 

Keywords: predictive modeling; structural earthquake damage; 2015 Nepal Earthquake; dimensionality reduction; data preprocessing 
![image](https://user-images.githubusercontent.com/93449247/184797673-6d7d2132-4d23-41d9-8203-3934aaf77c68.png)


